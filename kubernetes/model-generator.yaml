apiVersion: v1
kind: ConfigMap
metadata:
  name: model-generator
  namespace: weather-ops
data:
  generate_model.py: |
    import subprocess
    import sys

    # Install required packages
    subprocess.check_call([sys.executable, "-m", "pip", "install", "numpy", "scikit-learn", "pandas"])

    import pickle
    import numpy as np
    import pandas as pd
    from sklearn.ensemble import RandomForestRegressor
    import os

    # Create a weather dataset with MORE historical data (15 days)
    # This ensures we have enough data after creating lag features
    data = {
        'time': [f'2025-01-{i:02d}' for i in range(1, 16)],
        'tavg': [15.0, 16.0, 17.0, 16.5, 17.5, 18.0, 18.5, 17.8, 16.9, 17.2, 16.8, 17.3, 18.1, 17.9, 16.7],
        'tmin': [10.0, 11.0, 12.0, 11.5, 12.5, 13.0, 13.5, 12.8, 11.9, 12.2, 11.8, 12.3, 13.1, 12.9, 11.7],
        'tmax': [20.0, 21.0, 22.0, 21.5, 22.5, 23.0, 23.5, 22.8, 21.9, 22.2, 21.8, 22.3, 23.1, 22.9, 21.7],
        'prcp': [0.5, 0.0, 0.2, 0.1, 0.3, 0.0, 0.5, 0.2, 0.0, 0.3, 0.1, 0.4, 0.0, 0.3, 0.2],
        'wspd': [10.0, 12.0, 11.0, 10.5, 11.5, 12.5, 11.8, 10.9, 12.2, 11.5, 10.8, 11.3, 12.1, 11.9, 10.7]
    }
    
    # Create the DataFrame with the data
    df = pd.DataFrame(data)
    
    print("Creating initial dataset...")
    print(f"Initial data shape: {df.shape}")
    
    # Save the cleaned weather CSV to be used by the frontend
    os.makedirs('/app/data', exist_ok=True)
    df.to_csv('/app/data/cleaned_weather.csv', index=False)
    print(f"Created cleaned_weather.csv with {len(df)} rows of sample data")
    
    # Create lag features - matching the same pattern as in your train.py
    print("Creating lag features...")
    features_to_lag = ['tavg', 'tmin', 'tmax', 'prcp', 'wspd']
    for feature in features_to_lag:
        for lag in range(1, 4):  # 3 days of lag, same as your train.py
            df[f"{feature}_t-{lag}"] = df[feature].shift(lag)
    
    # Drop rows with NaN values
    df.dropna(inplace=True)
    print(f"After creating lag features, we have {len(df)} rows of data")
    print(f"Data columns after creating lag features: {df.columns.tolist()}")
    
    # Prepare features and target
    X = df.drop(columns=['time', 'tavg'])  # Same as your train.py
    y = df['tavg']
    
    print(f"Feature matrix X shape: {X.shape}")
    print(f"Target vector y shape: {y.shape}")
    
    # Create and train model - using RandomForestRegressor like your original code
    model = RandomForestRegressor(n_estimators=10, random_state=42)  # Using fewer estimators for speed
    model.fit(X, y)
    
    # Save model with version info - in the same format as your train.py
    with open('/app/data/model.pkl', 'wb') as f:
        pickle.dump(model, f)  # Just saving the model directly like frontend expects
    
    print("Model generated successfully!")
    print(f"Model features: {model.feature_names_in_}")
    print("Dataset shape that the model was trained on:", X.shape)
    print("This is a placeholder model for Kubernetes deployment only.")
    
    # Create a test prediction to ensure the model works
    try:
        test_pred = model.predict(X.iloc[:1])
        print(f"Test prediction succeeded: {test_pred[0]:.2f}")
    except Exception as e:
        print(f"Error during test prediction: {str(e)}")